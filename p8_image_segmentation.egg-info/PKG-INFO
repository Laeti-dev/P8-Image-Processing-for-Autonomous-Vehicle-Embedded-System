Metadata-Version: 2.4
Name: p8-image-segmentation
Version: 0.1.0
Summary: Image segmentation for autonomous vehicles (Cityscapes, 8 categories)
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: tensorflow>=2.10.0
Requires-Dist: tf-models-official
Requires-Dist: opencv-python<5.0.0,>=4.6.0
Requires-Dist: Pillow<11.0.0,>=9.0.0
Requires-Dist: albumentations<2.0.0,>=1.3.0
Requires-Dist: numpy<2.0.0,>=1.23.0
Requires-Dist: pandas<3.0.0,>=1.5.0
Requires-Dist: matplotlib<4.0.0,>=3.6.0
Requires-Dist: seaborn<1.0.0,>=0.12.0
Requires-Dist: mlflow==2.8.0
Requires-Dist: optuna<4.0.0,>=3.0.0
Requires-Dist: fastapi<1.0.0,>=0.95.0
Requires-Dist: uvicorn[standard]<1.0.0,>=0.20.0
Requires-Dist: python-multipart<1.0.0,>=0.0.6
Requires-Dist: pydantic<3.0.0,>=1.10.0
Requires-Dist: streamlit<2.0.0,>=1.25.0
Requires-Dist: tqdm<5.0.0,>=4.65.0
Requires-Dist: scikit-learn<2.0.0,>=1.2.0
Requires-Dist: jupyter<2.0.0,>=1.0.0
Requires-Dist: ipykernel<7.0.0,>=6.20.0
Requires-Dist: notebook<8.0.0,>=6.5.0
Requires-Dist: azure-storage-blob<13.0.0,>=12.14.0
Requires-Dist: azure-identity<2.0.0,>=1.12.0
Requires-Dist: scipy<2.0.0,>=1.9.0
Requires-Dist: imageio<3.0.0,>=2.25.0
Requires-Dist: python-dotenv<2.0.0,>=1.0.0
Requires-Dist: pytest<9.0.0,>=7.0.0

# P8-Image-Processing-for-Autonomous-Vehicle-Embedded-System

Development of embedded computer vision systems with the objective of gaining experience in image segmentation.

## üìã Project Documentation

This project includes the development of an image segmentation system for autonomous vehicles with:
- Semantic segmentation model (8 Cityscapes categories)
- Prediction API (FastAPI)
- Web demonstration application
- Complete technical documentation

**Project documentation** (plan, structure, Azure guide, etc.) is in the [docs/](docs/) directory.

## üìÅ Project Structure

- **`app/`** ‚Äî FastAPI inference API and Streamlit web app
- **`src/`** ‚Äî Core logic (model, data pipeline, callbacks, predictor)
- **`notebooks/`** ‚Äî Data exploration and training pipeline
- **`data/raw/`** ‚Äî Cityscapes dataset; **`data/samples/`** ‚Äî Sample images for demos
- **`models/`** ‚Äî Trained models and checkpoints
- **`outputs/`** ‚Äî Logs (TensorBoard), MLflow runs, predictions, training visualizations
- **`docs/`** ‚Äî Project documentation
- **`tests/`** ‚Äî Pytest tests

## üöÄ Setup

### Virtual Environment Setup

This project uses [UV](https://github.com/astral-sh/uv) for fast Python package management.

1. **Install UV (if not already installed):**
   ```bash
   pip install uv
   ```
   Or follow the [official installation guide](https://github.com/astral-sh/uv#installation).

2. **Create a virtual environment:**
   ```bash
   uv venv
   ```

3. **Activate the virtual environment:**
   - On macOS/Linux:
     ```bash
     source .venv/bin/activate
     ```
   - On Windows:
     ```bash
     .venv\Scripts\activate
     ```

4. **Install the project in editable mode** (recommended so `app` and `src` are importable):
   ```bash
   uv pip install -e .
   ```
   Or with requirements only: `uv pip install -r requirements.txt`

5. **Deactivate the virtual environment (when done):**
   ```bash
   deactivate
   ```

## üåê Running the API

The inference API loads the segmentation model from Azure at startup and serves `/health` and `/predict`.

**Run from the project root** (after `uv pip install -e .`):
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

**Environment variables** (copy `.env.example` to `.env` and set):

| Variable | Description | Default |
|----------|-------------|---------|
| `AZURE_MODEL_BLOB_NAME` | Blob path of the model in Azure | `model/best_model.keras` |
| `AZURE_CONTAINER_NAME` | Azure Blob Storage container name | `training-outputs` |
| `AZURE_STORAGE_CONNECTION_STRING` | Full connection string (recommended) | ‚Äî |
| `AZURE_STORAGE_ACCOUNT_NAME` | Account name (if not using connection string) | ‚Äî |
| `AZURE_STORAGE_ACCOUNT_KEY` | Account key (if not using connection string) | ‚Äî |

- **GET /health** ‚Äî Returns `{"status": "ok", "model_loaded": true/false}`.
- **POST /predict** ‚Äî Upload a PNG or JPEG image (max 20 MB); returns mask and colored mask as base64, plus categories.
   
## üìä Project Steps

The project follows a structured development approach:

1. **Data Exploration** - Analysis of the Cityscapes dataset structure, class distribution, and image characteristics
2. **Model Development** - Implementation of U-Net architecture for semantic segmentation with data augmentation
3. **Training Pipeline** - Model training with callbacks, metrics tracking, and visualization
4. **API Development** - FastAPI-based prediction service for real-time inference
5. **Web Application** - Streamlit-based demonstration interface for interactive predictions
6. **Documentation** - Technical documentation and presentation materials

## üîç Data Exploration

The data exploration phase (`notebooks/01-data_exploration.ipynb`) provides a comprehensive analysis of the Cityscapes dataset:

### Dataset Structure
- **Training set**: 2,964 images across 18 cities
- **Test set**: 1,525 images across 6 cities
- **Image dimensions**: Standardized 1024√ó2048 pixels (2:1 aspect ratio)

### Class Mapping
The exploration notebook implements a mapping from the original 34 Cityscapes classes to 8 main categories:
- **Void** (0): Unlabeled, ego vehicle, borders, and ignored regions
- **Flat** (1): Road, sidewalk, parking, rail track
- **Construction** (2): Building, wall, fence, guard rail, bridge, tunnel
- **Object** (3): Pole, traffic sign, traffic light
- **Nature** (4): Vegetation, terrain
- **Sky** (5): Sky regions
- **Human** (6): Person, rider
- **Vehicle** (7): Car, truck, bus, motorcycle, bicycle, and other vehicles

### Key Findings
- **Class imbalance**: Significant imbalance detected (52.5√ó ratio between most and least frequent classes)
  - Flat surfaces: ~39.3% of pixels
  - Construction: ~22.9% of pixels
  - Human class: ~0.75% of pixels (most underrepresented)
- **Recommendations**: Use class weights or focal loss during training to handle imbalance

### Utility Functions
The notebook creates reusable utility functions for:
- Loading Cityscapes images and masks
- Converting 34-class masks to 8-category masks
- Visualizing images with colored segmentation masks
- Path management for dataset files

These functions are exported to `src/utils.py` for use in the training pipeline.


### üìñ Resources

- Cityscapes Dataset: https://www.cityscapes-dataset.com/
- Keras Documentation: https://keras.io/
- FastAPI Documentation: https://fastapi.tiangolo.com/
- Streamlit Documentation: https://docs.streamlit.io/
