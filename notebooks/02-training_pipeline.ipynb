{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laeti-dev/P8-Image-Processing-for-Autonomous-Vehicle-Embedded-System/blob/master/notebooks/02-training_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdpyezEqB2QM"
      },
      "source": [
        "# Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Nfn-j5CC9d8"
      },
      "outputs": [],
      "source": [
        "# Mount drive and set path to data\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLm_jVuSB17J"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "USER = \"Laeti-dev\"\n",
        "REPO = \"P8-Image-Processing-for-Autonomous-Vehicle-Embedded-System\"\n",
        "TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "GIT_PATH = f\"https://{TOKEN}@github.com/{USER}/{REPO}.git\"\n",
        "WORKING_BRANCH = \"tests\"\n",
        "\n",
        "# Go to /content/\n",
        "%cd /content/\n",
        "\n",
        "# Clone or pull\n",
        "if not os.path.exists(REPO):\n",
        "    print(f\"Cloning {REPO}...\")\n",
        "    !git clone {GIT_PATH}\n",
        "    %cd {REPO}\n",
        "    if WORKING_BRANCH:\n",
        "        print(f\"Checking out branch: {WORKING_BRANCH}\")\n",
        "        !git checkout {WORKING_BRANCH}\n",
        "else:\n",
        "    print(f\"Repository {REPO} already exists. Pulling latest changes...\")\n",
        "    %cd {REPO}\n",
        "    if WORKING_BRANCH:\n",
        "        print(f\"Checking out branch: {WORKING_BRANCH}\")\n",
        "        !git checkout {WORKING_BRANCH}\n",
        "    !git pull\n",
        "\n",
        "%cd /content/{REPO}\n",
        "\n",
        "# Ensure the data_path_on_drive variable is accessible and correct\n",
        "data_path_on_drive = f'/content/drive/MyDrive/OC/Projets/P8/'\n",
        "\n",
        "# Unzip directly into the raw data directory on Google Drive, forcing overwrite (-o)\n",
        "!unzip -q -o /content/drive/MyDrive/OC/Projets/P8/data.zip -d {data_path_on_drive}\n",
        "\n",
        "\n",
        "if os.getcwd() not in sys.path:\n",
        "    sys.path.append(os.getcwd())\n",
        "\n",
        "import src.utils as utils\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2\n",
        "\n",
        "import src.utils as utils\n",
        "print(f\"Images are HERE : {utils.IMAGES_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "330933d5"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# directories_to_delete = [\n",
        "#     \"/content/P8-Image-Processing-for-Autonomous-Vehicle-Embedded-System\",\n",
        "#     \"/content/__MACOSX\",\n",
        "#     \"/content/raw\"\n",
        "# ]\n",
        "\n",
        "# for directory in directories_to_delete:\n",
        "#     if os.path.exists(directory):\n",
        "#         print(f\"Suppression du r√©pertoire : {directory}\")\n",
        "#         shutil.rmtree(directory)\n",
        "#         print(\"R√©pertoire supprim√© avec succ√®s.\")\n",
        "#     else:\n",
        "#         print(f\"Le r√©pertoire {directory} n'existe pas, pas de suppression n√©cessaire.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4LAHLG9ETUg"
      },
      "outputs": [],
      "source": [
        "# Install requirements\n",
        "!pip install python-dotenv albumentations mlflow fastparquet optuna azure-storage-blob --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJAk9WS2GmW1"
      },
      "outputs": [],
      "source": [
        "# Find secrets\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    COLAB = True\n",
        "except ImportError:\n",
        "    COLAB = False\n",
        "\n",
        "def get_secret(key, default):\n",
        "    if COLAB:\n",
        "        try:\n",
        "            # Get secrets from colab\n",
        "            return userdata.get(key)\n",
        "        except userdata.SecretNotFoundError:\n",
        "            return os.getenv(key)\n",
        "    else:\n",
        "        # Get secrets from .env\n",
        "        from dotenv import load_dotenv\n",
        "        load_dotenv()\n",
        "        return os.getenv(key, default)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_global_best_info(metrics_path, model_path=None):\n",
        "    \"\"\"\n",
        "    Load and return (or display) the current global best model info from the metrics file.\n",
        "\n",
        "    Args:\n",
        "        metrics_path: Path to global_best_metrics.json.\n",
        "        model_path: Optional path to the model file (used for existence check and display).\n",
        "\n",
        "    Returns:\n",
        "        dict with keys: val_iou_coefficient, run_name, timestamp, model_path, model_exists;\n",
        "        or None if no metrics file exists.\n",
        "    \"\"\"\n",
        "    metrics_path = Path(metrics_path)\n",
        "    if not metrics_path.exists():\n",
        "        print(\"No global best metrics file found. No best model has been saved yet.\")\n",
        "        return None\n",
        "    try:\n",
        "        with open(metrics_path, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading global best metrics: {e}\")\n",
        "        return None\n",
        "\n",
        "    model_path = Path(model_path) if model_path else metrics_path.parent / \"global_best_model.keras\"\n",
        "    info = {\n",
        "        \"val_iou_coefficient\": data.get(\"val_iou_coefficient\"),\n",
        "        \"run_name\": data.get(\"run_name\"),\n",
        "        \"timestamp\": data.get(\"timestamp\"),\n",
        "        \"model_path\": str(model_path),\n",
        "        \"model_exists\": model_path.exists(),\n",
        "    }\n",
        "    return info\n",
        "\n",
        "\n",
        "def print_global_best_info(metrics_path, model_path=None):\n",
        "    \"\"\"\n",
        "    Display the current global best model info in a readable format.\n",
        "\n",
        "    Args:\n",
        "        metrics_path: Path to global_best_metrics.json (e.g. GLOBAL_BEST_METRICS_PATH).\n",
        "        model_path: Optional path to the model file (default: same dir as metrics, global_best_model.keras).\n",
        "    \"\"\"\n",
        "    info = get_global_best_info(metrics_path, model_path)\n",
        "    if info is None:\n",
        "        return\n",
        "    print(\"Current global best model:\")\n",
        "    iou = info[\"val_iou_coefficient\"]\n",
        "    print(f\"  val_iou_coefficient: {iou:.4f}\" if iou is not None else \"  val_iou_coefficient: N/A\")\n",
        "    print(f\"  run_name:            {info['run_name']}\")\n",
        "    print(f\"  timestamp:           {info['timestamp']}\")\n",
        "    print(f\"  model_path:          {info['model_path']}\")\n",
        "    print(f\"  model_file_exists:   {info['model_exists']}\")"
      ],
      "metadata": {
        "id": "pZ97yISUPgN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xAweA0IBovF"
      },
      "source": [
        "# Training Pipeline - U-Net for Cityscapes Segmentation\n",
        "\n",
        "This notebook implements the complete training pipeline for semantic segmentation on the Cityscapes dataset.\n",
        "\n",
        "## Objectives\n",
        "- Create and compile the U-Net model\n",
        "- Set up data generators with augmentation\n",
        "- Train the model with callbacks\n",
        "- Visualize predictions during training\n",
        "- Monitor training metrics\n",
        "- Save the best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2zkxwBfBovG"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "\n",
        "\n",
        "COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if COLAB :\n",
        "  PROJECT_ROOT = Path(\"/content/P8-Image-Processing-for-Autonomous-Vehicle-Embedded-System\")\n",
        "else:\n",
        "  # Load environment variables from .env file\n",
        "  try:\n",
        "      from dotenv import load_dotenv\n",
        "      # Try to load .env from project root (parent of notebooks/)\n",
        "      # In notebooks, we're in notebooks/ directory, so go up one level\n",
        "      env_path = Path('..') / '.env'\n",
        "      if env_path.exists():\n",
        "          load_dotenv(env_path)\n",
        "          print(f\"‚úì Loaded environment variables from {env_path.resolve()}\")\n",
        "      else:\n",
        "          # Try current directory (notebooks/)\n",
        "          env_path = Path('.env')\n",
        "          if env_path.exists():\n",
        "              load_dotenv(env_path)\n",
        "              print(f\"‚úì Loaded environment variables from {env_path.resolve()}\")\n",
        "          else:\n",
        "              # Try project root from absolute path\n",
        "              import os\n",
        "              project_root = Path(os.path.abspath('..'))\n",
        "              env_path = project_root / '.env'\n",
        "              if env_path.exists():\n",
        "                  load_dotenv(env_path)\n",
        "                  print(f\"‚úì Loaded environment variables from {env_path}\")\n",
        "              else:\n",
        "                  print(\"‚ö† .env file not found. Make sure it exists in the project root.\")\n",
        "  except ImportError:\n",
        "      print(\"‚ö† python-dotenv not installed. Install with: pip install python-dotenv\")\n",
        "  except Exception as e:\n",
        "      print(f\"‚ö† Could not load .env file: {e}\")\n",
        "\n",
        "module_path = str(PROJECT_ROOT)\n",
        "\n",
        "if module_path not in sys.path:\n",
        "    sys.path.insert(0, module_path)\n",
        "    print(f\"‚úì Added to sys.path: {module_path}\")\n",
        "\n",
        "# MLflow tracking\n",
        "try:\n",
        "    from src.mlflow_tracking import MLflowTracker, setup_mlflow_tracking\n",
        "    from src.callbacks import MLflowCallback, MLflowVisualizationCallback, MLflowModelCallback\n",
        "    MLFLOW_AVAILABLE = True\n",
        "    print(\"‚úì MLflow tracking available\")\n",
        "except ImportError:\n",
        "    MLFLOW_AVAILABLE = False\n",
        "    print(\"‚ö† MLflow not available. Install with: pip install mlflow\")\n",
        "\n",
        "\n",
        "# TensorFlow/Keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import legacy\n",
        "from tensorflow.keras.callbacks import (\n",
        "    ModelCheckpoint,\n",
        "    EarlyStopping,\n",
        "    ReduceLROnPlateau,\n",
        "    TensorBoard\n",
        ")\n",
        "\n",
        "\n",
        "from src.model_architecture import build_unet, build_unet_small, build_unet_mobilenet, build_deeplabv3, build_deeplabv3_mobilenet\n",
        "from src.metrics import combined_loss, DiceCoefficient, IoUCoefficient\n",
        "from src.data_generator import create_data_generators # Now this will pick up updated paths\n",
        "from src.augmentations import get_training_augmentation, get_light_augmentation\n",
        "from src.callbacks import (\n",
        "    PredictionVisualizationFromGenerator,\n",
        "    TrainingTimeCallback,\n",
        "    AzureUploadCallback,\n",
        "    AzureModelCheckpoint\n",
        ")\n",
        "from src.azure_storage import AzureStorageManager\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "import tensorflow as tf\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7792d6ff"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "def update_global_best(history, model, run_name):\n",
        "    \"\"\"\n",
        "    Updates the global best model if the current run achieves a higher validation IoU.\n",
        "    \"\"\"\n",
        "    # Get the best validation IoU from the current run\n",
        "    if 'val_iou_coefficient' in history.history:\n",
        "        current_best_iou = np.max(history.history['val_iou_coefficient'])\n",
        "    else:\n",
        "        print(\"Warning: 'val_iou_coefficient' not found in history. Skipping global best update.\")\n",
        "        return\n",
        "\n",
        "    # Check for existing global best\n",
        "    global_best_iou = 0.0\n",
        "    if os.path.exists(GLOBAL_BEST_METRICS_PATH):\n",
        "        try:\n",
        "            with open(GLOBAL_BEST_METRICS_PATH, 'r') as f:\n",
        "                data = json.load(f)\n",
        "                global_best_iou = data.get('val_iou_coefficient', 0.0)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading global best metrics: {e}\")\n",
        "\n",
        "    print(f\"\\nCurrent run best val_iou: {current_best_iou:.4f}\")\n",
        "    print(f\"Previous global best val_iou: {global_best_iou:.4f}\")\n",
        "\n",
        "    # Update if current run is better\n",
        "    if current_best_iou > global_best_iou:\n",
        "        print(\"üèÜ New global best model found! Saving...\")\n",
        "        try:\n",
        "            # Save model\n",
        "            model.save(GLOBAL_BEST_MODEL_PATH)\n",
        "\n",
        "            # Save metrics\n",
        "            metrics_data = {\n",
        "                'val_iou_coefficient': float(current_best_iou),\n",
        "                'run_name': run_name,\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            }\n",
        "            with open(GLOBAL_BEST_METRICS_PATH, 'w') as f:\n",
        "                json.dump(metrics_data, f, indent=4)\n",
        "\n",
        "            print(f\"‚úì Global best model saved to {GLOBAL_BEST_MODEL_PATH}\")\n",
        "            print(f\"‚úì Metrics saved to {GLOBAL_BEST_METRICS_PATH}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving global best model/metrics: {e}\")\n",
        "    else:\n",
        "        print(f\"Current run did not beat global best ({global_best_iou:.4f}).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6379da0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "repo_path = \"/content/P8-Image-Processing-for-Autonomous-Vehicle-Embedded-System\"\n",
        "\n",
        "if os.path.exists(repo_path):\n",
        "    print(f\"Suppression du r√©pertoire : {repo_path}\")\n",
        "    shutil.rmtree(repo_path)\n",
        "    print(\"R√©pertoire supprim√© avec succ√®s.\")\n",
        "else:\n",
        "    print(f\"Le r√©pertoire {repo_path} n'existe pas.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwB7TewQBovH"
      },
      "source": [
        "## 1. Configuration\n",
        "\n",
        "Define hyperparameters and training settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_MvQqZ6BovH"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "IMAGE_SIZE = (256, 512)  # (height, width)\n",
        "BATCH_SIZE = 8\n",
        "N_CLASSES = 8\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "# Model configuration\n",
        "USE_SMALL_MODEL = False  # Set to True for faster\n",
        "USE_MOBILENET_BACKBONE = True\n",
        "USE_DEEPLABV3 = False\n",
        "USE_DEEPLABV3_WITH_BACKBONE = False\n",
        "# Validate that only one of the model configuration is True\n",
        "assert sum([USE_SMALL_MODEL, USE_MOBILENET_BACKBONE, USE_DEEPLABV3, USE_DEEPLABV3_WITH_BACKBONE]) <= 1, \"Only one model configuration can be True\"\n",
        "INITIAL_FILTERS = 64  # Number of filters in first layer\n",
        "MOBILENET_ALPHA = 1.0  # MobileNet width multiplier (1.0, 0.75, 0.5, 0.35)\n",
        "MOBILENET_WEIGHTS = \"imagenet\"  # Pre-trained weights: \"imagenet\" or None\n",
        "DECODER_FILTERS = 256  # Number of filters in decoder (for MobileNet backbone)\n",
        "FREEZE_BACKBONE = True  # Phase 1: freeze encoder, train only decoder\n",
        "FINE_TUNING_LR = 1e-5  # Phase 2: lower learning rate for fine-tuning entire model\n",
        "\n",
        "# Augmentation\n",
        "USE_AUGMENTATION = True\n",
        "USE_LIGHT_AUGMENTATION = False  # Set to True for faster training\n",
        "\n",
        "# Callbacks configuration\n",
        "VISUALIZE_PREDICTIONS = True\n",
        "VIZ_FREQUENCY = 10  # Visualize every N epochs\n",
        "EARLY_STOPPING_PATIENCE = 20\n",
        "REDUCE_LR_PATIENCE = 5\n",
        "\n",
        "MODEL = \"deeplab\" if (USE_DEEPLABV3_WITH_BACKBONE or USE_DEEPLABV3) else \"unet&mobilenet\" if USE_MOBILENET_BACKBONE else \"unet\"\n",
        "\n",
        "# Paths\n",
        "IS_COLAB = 'COLAB_GPU' in os.environ or 'COLAB_JUPYTER_IP' in os.environ\n",
        "\n",
        "if IS_COLAB:\n",
        "    checkpoint_dir = f\"/content/drive/MyDrive/OC/Projets/P8/checkpoints/{MODEL}\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    base = data_path_on_drive\n",
        "\n",
        "    BEST_MODEL_PATH = os.path.join(checkpoint_dir, \"best_model.keras\")\n",
        "    LAST_MODEL_PATH = os.path.join(checkpoint_dir, \"last_epoch_checkpoint.keras\")\n",
        "\n",
        "    # Global best model configuration\n",
        "    global_best_dir = \"/content/drive/MyDrive/OC/Projets/P8/checkpoints/global_best\"\n",
        "    os.makedirs(global_best_dir, exist_ok=True)\n",
        "    GLOBAL_BEST_MODEL_PATH = os.path.join(global_best_dir, \"global_best_model.keras\")\n",
        "    GLOBAL_BEST_METRICS_PATH = os.path.join(global_best_dir, \"global_best_metrics.json\")\n",
        "    print(f\"Global best model path: {GLOBAL_BEST_MODEL_PATH}\")\n",
        "\n",
        "else:\n",
        "    checkpoint_dir = f\"./models/checkpoints/{MODEL}\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    base = \"\"\n",
        "\n",
        "    BEST_MODEL_PATH = os.path.join(checkpoint_dir, \"best_model.keras\")\n",
        "    # Fallback for local run\n",
        "    GLOBAL_BEST_MODEL_PATH = os.path.join(checkpoint_dir, \"global_best_model.keras\")\n",
        "    GLOBAL_BEST_METRICS_PATH = os.path.join(checkpoint_dir, \"global_best_metrics.json\")\n",
        "\n",
        "print(f\"Sauvegarde des mod√®les dans : {checkpoint_dir}\")\n",
        "MODEL_SAVE_PATH = f\"{base}models/{MODEL}\"\n",
        "OUTPUT_DIR = f\"{base}outputs/training_visualizations/{MODEL}\"\n",
        "LOGS_DIR = f\"{base}logs/{MODEL}\"\n",
        "\n",
        "print_global_best_info(GLOBAL_BEST_METRICS_PATH, GLOBAL_BEST_MODEL_PATH)\n",
        "\n",
        "# Azure Storage configuration\n",
        "USE_AZURE_STORAGE = True  # Set to True to enable Azure uploads\n",
        "AZURE_CONTAINER_NAME = \"training-outputs\"\n",
        "AZURE_RUN_NAME = \"MobileNetV2\"  # Optional: name for this training run (e.g., \"experiment_001\")\n",
        "AZURE_UPLOAD_FREQUENCY = 1  # Upload every N epochs (1 = every epoch)\n",
        "AZURE_ONLY_MODE = True  # Set to True to save ONLY to Azure (no local saves)\n",
        "AZURE_CREATE_CONTAINER = False  # Set to True to auto-create container (requires permissions)\n",
        "                                 # If False, container must exist already\n",
        "\n",
        "# MLflow configuration\n",
        "USE_MLFLOW = True  # Set to True to enable MLflow tracking\n",
        "mlflow_tracker = None\n",
        "\n",
        "if USE_MLFLOW:\n",
        "  if \"google.colab\" in sys.modules:\n",
        "    try:\n",
        "            DAGSHUB_USER = userdata.get('DAGSHUB_USERNAME')\n",
        "            if DAGSHUB_USER:\n",
        "                DAGSHUB_USER = DAGSHUB_USER.replace('\\r', '').replace('\\n', '').strip() # Aggressively clean\n",
        "            DAGSHUB_TOKEN = userdata.get('DAGSHUB_TOKEN')\n",
        "            DAGSHUB_REPO = userdata.get('DAGSHUB_REPO_NAME')\n",
        "            if DAGSHUB_REPO:\n",
        "                DAGSHUB_REPO = DAGSHUB_REPO.replace('\\r', '').replace('\\n', '').strip() # Aggressively clean\n",
        "\n",
        "            os.environ['MLFLOW_TRACKING_USERNAME'] = DAGSHUB_USER\n",
        "            os.environ['MLFLOW_TRACKING_PASSWORD'] = DAGSHUB_TOKEN\n",
        "\n",
        "            MLFLOW_TRACKING_URI = f\"https://dagshub.com/{DAGSHUB_USER}/{DAGSHUB_REPO}.mlflow\"\n",
        "            print(f\"‚úì DagsHub configuration detected for Colab\")\n",
        "\n",
        "    except Exception as e:\n",
        "            print(f\"‚ö† Erreur Secrets Colab : {e}. Repli sur localhost.\")\n",
        "            MLFLOW_TRACKING_URI = 'http://localhost:5001'\n",
        "  else:\n",
        "    # MLflow configuration from environment variables\n",
        "    MLFLOW_TRACKING_URI = get_secret('MLFLOW_TRACKING_URI', 'http://localhost:5001')\n",
        "\n",
        "if MLFLOW_TRACKING_URI and ' ' in MLFLOW_TRACKING_URI:\n",
        "    MLFLOW_TRACKING_URI = MLFLOW_TRACKING_URI.split(' ')[0]\n",
        "MLFLOW_EXPERIMENT_NAME = get_secret('MLFLOW_EXPERIMENT_NAME', 'unet_cityscapes_segmentation')\n",
        "if MLFLOW_EXPERIMENT_NAME:\n",
        "    MLFLOW_EXPERIMENT_NAME = MLFLOW_EXPERIMENT_NAME.replace('\\r', '').replace('\\n', '').strip()\n",
        "\n",
        "# Create directories\n",
        "Path(\"models\").mkdir(exist_ok=True)\n",
        "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(LOGS_DIR).mkdir(exist_ok=True)\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Image size: {IMAGE_SIZE}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
        "if USE_MOBILENET_BACKBONE:\n",
        "    print(f\"  Model: U-Net with MobileNetV2 backbone (alpha={MOBILENET_ALPHA})\")\n",
        "elif USE_DEEPLABV3:\n",
        "    print(f\"  Model: DeepLabV3\")\n",
        "elif USE_DEEPLABV3_WITH_BACKBONE:\n",
        "    print(f\"  Model: DeepLabV3 with MobileNetV2 backbone\")\n",
        "else:\n",
        "    print(f\"  Model: {'Small' if USE_SMALL_MODEL else 'Full'} U-Net\")\n",
        "print(f\"  Augmentation: {'Light' if USE_LIGHT_AUGMENTATION else 'Full' if USE_AUGMENTATION else 'None'}\")\n",
        "print(f\"  Azure Storage: {'Enabled' if USE_AZURE_STORAGE else 'Disabled'}\")\n",
        "if USE_AZURE_STORAGE:\n",
        "    print(f\"    Container: {AZURE_CONTAINER_NAME}\")\n",
        "    print(f\"    Run name: {AZURE_RUN_NAME or 'default'}\")\n",
        "    print(f\"    Upload frequency: every {AZURE_UPLOAD_FREQUENCY} epoch(s)\")\n",
        "    print(f\"    Azure-only mode: {'Yes (no local saves)' if AZURE_ONLY_MODE else 'No (local + Azure)'}\")\n",
        "    print(f\"    Auto-create container: {'Yes' if AZURE_CREATE_CONTAINER else 'No (must exist)'}\")\n",
        "if USE_MLFLOW and MLFLOW_AVAILABLE:\n",
        "    # Initialize MLflow tracking\n",
        "    mlflow_tracker = setup_mlflow_tracking(\n",
        "        tracking_uri=MLFLOW_TRACKING_URI,\n",
        "        experiment_name=MLFLOW_EXPERIMENT_NAME\n",
        "    )\n",
        "    print(\"‚úì MLflow experiment tracking enabled\")\n",
        "    print(f\"    MLflow tracking URI: {MLFLOW_TRACKING_URI}\")\n",
        "    print(f\"    MLflow experiment name: {MLFLOW_EXPERIMENT_NAME}\")\n",
        "else:\n",
        "    print(\"‚ö† MLflow not available. Install with: pip install mlflow\")\n",
        "    print(f\"Experiment : {MLFLOW_EXPERIMENT_NAME}\")\n",
        "    print(f\"Tracking URI: {MLFLOW_TRACKING_URI}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq0XUi_PBovH"
      },
      "source": [
        "## 2. Create Data Generators\n",
        "\n",
        "Set up training and validation data generators with optional augmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from typing import Tuple, Optional, Sequence\n",
        "\n",
        "dropout = A.OneOf([\n",
        "            A.CoarseDropout(num_holes_range=(1, 8), hole_height_range=(0.1, 0.25),\n",
        "                            hole_width_range=(0.1, 0.25), fill_value=0, p=1.0),\n",
        "            # GridDropout requires integer pixel values for unit_size_min/max, not floats\n",
        "            A.GridDropout(ratio=0.5, unit_size_min=30, unit_size_max=60, p=1.0)\n",
        "        ], p=0.5)\n",
        "\n",
        "colors = A.OneOf([\n",
        "            A.ToGray(p=1.0), # p=1.0 inside OneOf\n",
        "            A.ChannelDropout(p=1.0) # p=1.0 inside OneOf\n",
        "        ], p=0.1)\n",
        "\n",
        "affine = A.Affine(\n",
        "            scale=(0.8, 1.2),      # Zoom in/out by 80-120%\n",
        "            rotate=(-15, 15),      # Rotate by -15 to +15 degrees\n",
        "            # translate_percent=(0, 0.1), # Optional: translate by 0-10%\n",
        "            # shear=(-10, 10),          # Optional: shear by -10 to +10 degrees\n",
        "            p=0.7\n",
        "        )\n",
        "\n",
        "transform1 = [dropout]\n",
        "transform2 = [dropout, colors]\n",
        "transform3 = [affine, dropout, colors]\n",
        "\n",
        "def get_training_augmentation(\n",
        "    image_size: Tuple[int, int],\n",
        "    p: float = 0.5,\n",
        "    extra_transforms: Optional[Sequence[A.BasicTransform]] = None,\n",
        ") -> A.Compose:\n",
        "    transforms = [\n",
        "        A.HorizontalFlip(p=p),\n",
        "    ]\n",
        "    if extra_transforms:\n",
        "        transforms.extend(extra_transforms)\n",
        "    return A.Compose(transforms)"
      ],
      "metadata": {
        "id": "y0nlV9yIjAch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92H4xSnYBovH"
      },
      "outputs": [],
      "source": [
        "# Create augmentation pipeline\n",
        "if USE_AUGMENTATION:\n",
        "    if USE_LIGHT_AUGMENTATION:\n",
        "        train_aug = get_light_augmentation(image_size=IMAGE_SIZE)\n",
        "        print(\"Using light augmentation\")\n",
        "    else:\n",
        "        train_aug = get_training_augmentation(image_size=IMAGE_SIZE, extra_transforms=transform3)\n",
        "        print(\"Using augmentation with extra\")\n",
        "else:\n",
        "    train_aug = None\n",
        "    print(\"No augmentation\")\n",
        "\n",
        "# Create data generators\n",
        "print(\"\\nCreating data generators...\")\n",
        "\n",
        "if 'data_path_on_drive' in globals() and os.path.exists(data_path_on_drive):\n",
        "    from pathlib import Path\n",
        "    utils.IMAGES_DIR = Path(data_path_on_drive) / 'data' / 'raw' / 'leftImg8bit'\n",
        "    utils.MASKS_DIR = Path(data_path_on_drive) / 'data' / 'raw' / 'gtFine'\n",
        "    print(f\"Overriding utils.IMAGES_DIR to: {utils.IMAGES_DIR}\")\n",
        "    print(f\"Overriding utils.MASKS_DIR to: {utils.MASKS_DIR}\")\n",
        "else:\n",
        "    print(\"Warning: data_path_on_drive not found or invalid. Using default utils paths.\")\n",
        "\n",
        "train_gen, val_gen = create_data_generators(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dim=IMAGE_SIZE,\n",
        "    augmentation=train_aug,\n",
        "    normalize=True,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        "    max_samples=None  # Use all data, or set a limit (e.g., 1000) for testing\n",
        ")\n",
        "\n",
        "print(f\"\\nData generators created:\")\n",
        "print(f\"  Training batches per epoch: {len(train_gen)}\")\n",
        "print(f\"  Validation batches per epoch: {len(val_gen)}\")\n",
        "print(f\"  Samples per batch: {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n01egHjjBovI"
      },
      "source": [
        "## 3. Test Data Generator\n",
        "\n",
        "Let's verify that the data generator works correctly by visualizing a batch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDOxWA3iwXEB"
      },
      "source": [
        "### Visualize augmented samples\n",
        "\n",
        "Below we load a few raw images and apply the augmentation pipeline several times to show how the same image can be transformed. This helps verify that image and mask stay aligned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMQ-C82SBovI"
      },
      "outputs": [],
      "source": [
        "# Test the data generator\n",
        "from src.utils import mask_to_colored\n",
        "\n",
        "# Get a batch\n",
        "images, masks = train_gen[0]\n",
        "\n",
        "print(f\"Batch shape - Images: {images.shape}, Masks: {masks.shape}\")\n",
        "print(f\"Image dtype: {images.dtype}, range: [{images.min():.2f}, {images.max():.2f}]\")\n",
        "print(f\"Mask dtype: {masks.dtype}, unique values: {np.unique(masks)}\")\n",
        "\n",
        "# Visualize a few samples\n",
        "n_samples = min(4, len(images))\n",
        "fig, axes = plt.subplots(n_samples, 3, figsize=(15, 5 * n_samples))\n",
        "\n",
        "if n_samples == 1:\n",
        "    axes = axes.reshape(1, -1)\n",
        "\n",
        "for i in range(n_samples):\n",
        "    # Denormalize image\n",
        "    img = (images[i] * 255).astype(np.uint8) if images[i].max() <= 1.0 else images[i].astype(np.uint8)\n",
        "    mask = masks[i].astype(np.uint8)\n",
        "    colored_mask = mask_to_colored(mask)\n",
        "\n",
        "    # Original image\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f\"Sample {i+1}: Image\")\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Ground truth mask\n",
        "    axes[i, 1].imshow(colored_mask)\n",
        "    axes[i, 1].set_title(f\"Sample {i+1}: Ground Truth\")\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    # Overlay\n",
        "    overlay = (img * 0.6 + colored_mask * 0.4).astype(np.uint8)\n",
        "    axes[i, 2].imshow(overlay)\n",
        "    axes[i, 2].set_title(f\"Sample {i+1}: Overlay\")\n",
        "    axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Data generator test successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6LMFh3lBovI"
      },
      "source": [
        "## 4. Build and Compile Model\n",
        "\n",
        "Create the U-Net architecture and compile it with loss and metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoQGXneEBovI"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "print(\"Building model...\")\n",
        "if USE_MOBILENET_BACKBONE:\n",
        "    model = build_unet_mobilenet(\n",
        "        input_shape=(*IMAGE_SIZE, 3),\n",
        "        n_classes=N_CLASSES,\n",
        "        alpha=MOBILENET_ALPHA,\n",
        "        weights=MOBILENET_WEIGHTS,\n",
        "        decoder_filters=DECODER_FILTERS,\n",
        "        freeze_backbone=FREEZE_BACKBONE\n",
        "    )\n",
        "    print(f\"Using U-Net with MobileNetV2 backbone (alpha={MOBILENET_ALPHA})\")\n",
        "    print(f\"  Backbone frozen: {FREEZE_BACKBONE}\")\n",
        "elif USE_SMALL_MODEL:\n",
        "    model = build_unet_small(\n",
        "        input_shape=(*IMAGE_SIZE, 3),\n",
        "        n_classes=N_CLASSES,\n",
        "        filters=32\n",
        "    )\n",
        "    print(\"Using small U-Net model\")\n",
        "elif USE_DEEPLABV3:\n",
        "    model = build_deeplabv3(\n",
        "        input_shape=(*IMAGE_SIZE, 3),\n",
        "        n_classes=N_CLASSES,\n",
        "        weights=MOBILENET_WEIGHTS,\n",
        "        aspp_filters=DECODER_FILTERS,\n",
        "        freeze_backbone=FREEZE_BACKBONE\n",
        "    )\n",
        "    print(\"Using DeepLabV3 model\")\n",
        "    print(f\"  Backbone frozen: {FREEZE_BACKBONE}\")\n",
        "elif USE_DEEPLABV3_WITH_BACKBONE:\n",
        "    model = build_deeplabv3_mobilenet(\n",
        "        input_shape=(*IMAGE_SIZE, 3),\n",
        "        n_classes=N_CLASSES,\n",
        "        alpha=MOBILENET_ALPHA,\n",
        "        weights=MOBILENET_WEIGHTS,\n",
        "        aspp_filters=DECODER_FILTERS,\n",
        "        freeze_backbone=FREEZE_BACKBONE\n",
        "    )\n",
        "    print(\"Using DeepLabV3 with MobileNetV2 backbone\")\n",
        "    print(f\"  Backbone frozen: {FREEZE_BACKBONE}\")\n",
        "else:\n",
        "    model = build_unet(\n",
        "        input_shape=(*IMAGE_SIZE, 3),\n",
        "        n_classes=N_CLASSES,\n",
        "        filters=INITIAL_FILTERS\n",
        "    )\n",
        "    print(\"Using full U-Net model\")\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "    loss=combined_loss,\n",
        "    metrics=[\n",
        "        DiceCoefficient(),\n",
        "        IoUCoefficient()\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"Model output shape: {model.output.shape}\")\n",
        "\n",
        "print(\"\\nModel compiled successfully!\")\n",
        "print(f\"\\nModel summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Calculate total parameters\n",
        "total_params = model.count_params()\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNUA5jeQBovI"
      },
      "source": [
        "## 5.MLFLOW Setup\n",
        "\n",
        "- Initialize MLflow tracker\n",
        "- Start run with dynamic name\n",
        "- Log configuration\n",
        "- Display connexion informations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZXOB0mxBovI"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "if USE_MLFLOW and mlflow_tracker:\n",
        "    # Start MLflow run\n",
        "    run_name = f\"Aug-t3-U-Net_MNV2_traindecoder20e_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    mlflow_tracker.start_run(run_name=run_name)\n",
        "\n",
        "    # Log configuration parameters\n",
        "    mlflow_tracker.log_params({\n",
        "        \"image_size\": str(IMAGE_SIZE),\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"learning_rate\": LEARNING_RATE,\n",
        "        \"model_type\": \"MobileNetV2\" if USE_MOBILENET_BACKBONE else \"SmallUNet\",\n",
        "        \"mobilenet_alpha\": MOBILENET_ALPHA,\n",
        "        \"augmentation\": \"Light\" if USE_LIGHT_AUGMENTATION else \"Full\" if USE_AUGMENTATION else \"None\"\n",
        "    })\n",
        "\n",
        "    # Log system info\n",
        "    mlflow_tracker.log_system_info()\n",
        "else:\n",
        "    print(\"MLflow tracking is disabled or tracker not initialized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrpBs6r4BovJ"
      },
      "source": [
        "## 6. Set Up Callbacks\n",
        "\n",
        "Configure callbacks for model checkpointing, early stopping, learning rate reduction, and visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIAvNvXiBovJ"
      },
      "outputs": [],
      "source": [
        "IS_COLAB = 'COLAB_GPU' in os.environ or 'COLAB_JUPYTER_IP' in os.environ\n",
        "# Create callbacks list\n",
        "callbacks = []\n",
        "\n",
        "# Model checkpoint - save best model\n",
        "if USE_AZURE_STORAGE and AZURE_ONLY_MODE:\n",
        "    # Save directly to Azure only (no local save)\n",
        "    try:\n",
        "        azure_manager = AzureStorageManager(\n",
        "            container_name=AZURE_CONTAINER_NAME,\n",
        "            create_container_if_not_exists=AZURE_CREATE_CONTAINER\n",
        "        )\n",
        "        from pathlib import Path\n",
        "        model_blob_name = f\"model/{Path(MODEL_SAVE_PATH).name}\"\n",
        "        azure_checkpoint = AzureModelCheckpoint(\n",
        "            azure_manager=azure_manager,\n",
        "            blob_name=model_blob_name,\n",
        "            monitor='val_iou_coefficient',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1,\n",
        "            run_name=AZURE_RUN_NAME\n",
        "        )\n",
        "        callbacks.append(azure_checkpoint)\n",
        "        print(\"Using Azure-only model checkpoint (no local saves)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Failed to initialize Azure checkpoint: {e}\")\n",
        "        print(\"Falling back to local checkpoint...\")\n",
        "        callbacks.append(\n",
        "            ModelCheckpoint(\n",
        "                BEST_MODEL_PATH,\n",
        "                monitor='val_iou_coefficient',\n",
        "                save_best_only=True,\n",
        "                mode='max',\n",
        "                verbose=1,\n",
        "                save_weights_only=False\n",
        "            )\n",
        "        )\n",
        "else:\n",
        "    # Save locally (and optionally upload to Azure later)\n",
        "    callbacks.append(\n",
        "        ModelCheckpoint(\n",
        "            BEST_MODEL_PATH,\n",
        "            monitor='val_iou_coefficient',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1,\n",
        "            save_weights_only=False\n",
        "        )\n",
        "    )\n",
        "    if IS_COLAB:\n",
        "      callbacks.append(\n",
        "        ModelCheckpoint(\n",
        "            LAST_MODEL_PATH,\n",
        "            monitor='val_iou_coefficient',\n",
        "            save_best_only=False,\n",
        "            verbose=0,\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Early stopping\n",
        "callbacks.append(\n",
        "    EarlyStopping(\n",
        "        monitor='val_iou_coefficient',\n",
        "        patience=EARLY_STOPPING_PATIENCE,\n",
        "        mode='max',\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        ")\n",
        "\n",
        "# Reduce learning rate on plateau\n",
        "callbacks.append(\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=REDUCE_LR_PATIENCE,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        ")\n",
        "\n",
        "# TensorBoard\n",
        "callbacks.append(\n",
        "    TensorBoard(\n",
        "        log_dir=LOGS_DIR,\n",
        "        histogram_freq=1,\n",
        "        write_graph=True,\n",
        "        update_freq='epoch'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Training time tracking callback\n",
        "time_callback = TrainingTimeCallback()\n",
        "callbacks.append(time_callback)\n",
        "\n",
        "# Prediction visualization callback\n",
        "if VISUALIZE_PREDICTIONS:\n",
        "    viz_callback = PredictionVisualizationFromGenerator(\n",
        "        validation_generator=val_gen,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        num_samples=4,\n",
        "        frequency=VIZ_FREQUENCY\n",
        "    )\n",
        "    callbacks.append(viz_callback)\n",
        "    print(f\"Visualization callback added (every {VIZ_FREQUENCY} epochs)\")\n",
        "\n",
        "# Azure Storage upload callback\n",
        "# Only add if not in Azure-only mode (in Azure-only mode, checkpoints are already saved to Azure)\n",
        "if USE_AZURE_STORAGE and not AZURE_ONLY_MODE:\n",
        "    try:\n",
        "        azure_manager = AzureStorageManager(\n",
        "            container_name=AZURE_CONTAINER_NAME,\n",
        "            create_container_if_not_exists=AZURE_CREATE_CONTAINER\n",
        "        )\n",
        "        azure_callback = AzureUploadCallback(\n",
        "            azure_manager=azure_manager,\n",
        "            model_path=MODEL_SAVE_PATH,\n",
        "            output_dir=OUTPUT_DIR,\n",
        "            logs_dir=LOGS_DIR,\n",
        "            run_name=AZURE_RUN_NAME,\n",
        "            upload_frequency=AZURE_UPLOAD_FREQUENCY\n",
        "        )\n",
        "        callbacks.append(azure_callback)\n",
        "        print(f\"Azure upload callback added (every {AZURE_UPLOAD_FREQUENCY} epoch(s))\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Failed to initialize Azure Storage: {e}\")\n",
        "        print(\"Continuing without Azure upload...\")\n",
        "elif USE_AZURE_STORAGE and AZURE_ONLY_MODE:\n",
        "    # In Azure-only mode, still upload outputs and logs (but not model, already handled)\n",
        "    try:\n",
        "        azure_manager = AzureStorageManager(\n",
        "            container_name=AZURE_CONTAINER_NAME,\n",
        "            create_container_if_not_exists=AZURE_CREATE_CONTAINER\n",
        "        )\n",
        "        azure_callback = AzureUploadCallback(\n",
        "            azure_manager=azure_manager,\n",
        "            model_path=None,  # Model already saved by AzureModelCheckpoint\n",
        "            output_dir=OUTPUT_DIR,\n",
        "            logs_dir=LOGS_DIR,\n",
        "            run_name=AZURE_RUN_NAME,\n",
        "            upload_frequency=AZURE_UPLOAD_FREQUENCY\n",
        "        )\n",
        "        callbacks.append(azure_callback)\n",
        "        print(f\"Azure upload callback added for outputs/logs (every {AZURE_UPLOAD_FREQUENCY} epoch(s))\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Failed to initialize Azure Storage: {e}\")\n",
        "        print(\"Continuing without Azure upload...\")\n",
        "\n",
        "if USE_MLFLOW and mlflow_tracker and MLFLOW_AVAILABLE:\n",
        "    # Main metrics callback\n",
        "    callbacks.append(MLflowCallback(tracker=mlflow_tracker))\n",
        "\n",
        "    # Visualization callback for MLflow\n",
        "    if VISUALIZE_PREDICTIONS:\n",
        "        callbacks.append(MLflowVisualizationCallback(\n",
        "            mlflow_tracker=mlflow_tracker,\n",
        "            visualization_dir=OUTPUT_DIR\n",
        "        ))\n",
        "\n",
        "    # Model logging callback - MODIFIED TO EXPLICITLY SAVE .keras FILE\n",
        "    # Using a custom class to avoid the MLflow/Keras 3 direct log_model incompatibility\n",
        "    class CustomMLflowModelCallback(MLflowModelCallback):\n",
        "        def on_train_end(self, logs=None):\n",
        "            import os\n",
        "            import tempfile\n",
        "            import mlflow\n",
        "            from mlflow import log_artifact\n",
        "\n",
        "            if self.save_model_at_end:\n",
        "                # Create a temporary file path with .keras extension\n",
        "                with tempfile.TemporaryDirectory() as tmpdir:\n",
        "                    temp_model_path = os.path.join(tmpdir, f\"{self.model_name}.keras\")\n",
        "                    self.model.save(temp_model_path)\n",
        "                    print(f\"‚úì Model saved temporarily to {temp_model_path}\")\n",
        "\n",
        "                    # Log the temporary .keras file as an artifact\n",
        "                    log_artifact(temp_model_path, artifact_path=self.model_name)\n",
        "                    print(f\"‚úì Logged model '{self.model_name}.keras' to MLflow\")\n",
        "            # Ensure the original on_train_end of the parent MLflowCallback is not called if it exists\n",
        "            # to prevent double logging or conflicts.\n",
        "\n",
        "    callbacks.append(CustomMLflowModelCallback(\n",
        "        mlflow_tracker=mlflow_tracker,\n",
        "        model_name=\"unet_mobilenet_cityscapes\"\n",
        "    ))\n",
        "    print(\"‚úì MLflow callbacks added\")\n",
        "\n",
        "print(f\"\\nTotal callbacks: {len(callbacks)}\")\n",
        "print(\"Callbacks configured:\")\n",
        "for i, cb in enumerate(callbacks, 1):\n",
        "    print(f\"  {i}. {cb.__class__.__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgZkuutmBovJ"
      },
      "source": [
        "## 6. Train the Model\n",
        "\n",
        "Start the training process. The model will automatically:\n",
        "- Save the best model based on validation IoU\n",
        "- Stop early if no improvement\n",
        "- Reduce learning rate when plateau is reached\n",
        "- Visualize predictions periodically\n",
        "- When using Google colab, save the last model as a checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw5VlNOoBovJ"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Check and update global best model\n",
        "print(\"\\nChecking for global best model...\")\n",
        "if 'update_global_best' in globals():\n",
        "    update_global_best(history, model, \"Phase1_Training\")\n",
        "else:\n",
        "    print(\"update_global_best function not defined. Skipping global best check.\")\n",
        "\n",
        "# End MLflow run\n",
        "if USE_MLFLOW and mlflow_tracker:\n",
        "    mlflow_tracker.end_run()\n",
        "print(\"=\" * 60)\n",
        "print(\"Training completed!\")\n",
        "print(f\"\\nBest model saved to: {MODEL_SAVE_PATH}\")\n",
        "if VISUALIZE_PREDICTIONS:\n",
        "    print(f\"Visualizations saved to: {OUTPUT_DIR}/\")\n",
        "print(f\"TensorBoard logs saved to: {LOGS_DIR}/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7CWJbXBbc3G"
      },
      "source": [
        "## 6.0 Phase 2: Fine-Tuning (Optional)\n",
        "\n",
        "If the model was trained with a frozen backbone (Phase 1), this step unfreezes the encoder\n",
        "and continues training with a **much lower learning rate** to fine-tune the entire network.\n",
        "\n",
        "**Important:** Only run this cell if `FREEZE_BACKBONE = True` was used during Phase 1.\n",
        "The lower learning rate prevents destroying the pretrained features while allowing\n",
        "the backbone to adapt to the segmentation task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHuFEgBBbc3G"
      },
      "outputs": [],
      "source": [
        "# Phase 2: Fine-tuning - unfreeze backbone and train with lower learning rate\n",
        "# Applies to any model that uses a frozen MobileNetV2 backbone:\n",
        "# - U-Net + MobileNetV2\n",
        "# - DeepLabV3 (always uses MobileNetV2 backbone)\n",
        "# - DeepLabV3 with MobileNetV2 backbone (convenience wrapper)\n",
        "uses_backbone = USE_MOBILENET_BACKBONE or USE_DEEPLABV3 or USE_DEEPLABV3_WITH_BACKBONE\n",
        "\n",
        "if uses_backbone and FREEZE_BACKBONE:\n",
        "    # Determine model type name for logging\n",
        "    if USE_MOBILENET_BACKBONE:\n",
        "        model_type = \"UNet_MobileNetV2\"\n",
        "    elif USE_DEEPLABV3:\n",
        "        model_type = \"DeepLabV3\"\n",
        "    elif USE_DEEPLABV3_WITH_BACKBONE:\n",
        "        model_type = \"DeepLabV3_MobileNetV2\"\n",
        "\n",
        "    if USE_AUGMENTATION:\n",
        "      model_type = \"Aug-t3\" + model_type\n",
        "    elif USE_LIGHT_AUGMENTATION:\n",
        "      model_type = \"LightAugmented\" + model_type\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Phase 2: Fine-tuning the entire {model_type} model\")\n",
        "    print(f\"  Unfreezing backbone...\")\n",
        "    print(f\"  Fine-tuning learning rate: {FINE_TUNING_LR}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Unfreeze all layers EXCEPT BatchNormalization.\n",
        "    # BN layers must stay frozen during fine-tuning because:\n",
        "    # - When trainable, BN recomputes statistics from each mini-batch\n",
        "    # - With small batches (e.g. 8), these statistics are noisy and unstable\n",
        "    # - This destabilizes the pretrained backbone and causes a loss spike\n",
        "    # Keeping BN frozen preserves the stable ImageNet statistics.\n",
        "    #\n",
        "    # IMPORTANT: We must traverse layers recursively because MobileNetV2\n",
        "    # may be nested as a sub-model inside the main model.\n",
        "    # ALSO: A sub-model's trainable=False OVERRIDES individual layer\n",
        "    # settings. So we must first set the sub-model to trainable=True\n",
        "    # (which propagates to all its layers), then freeze BN individually.\n",
        "    def unfreeze_except_bn(target_model):\n",
        "        for layer in target_model.layers:\n",
        "            if hasattr(layer, 'layers'):\n",
        "                # This is a nested sub-model (e.g. MobileNetV2).\n",
        "                # Setting trainable=True propagates to ALL its sublayers.\n",
        "                layer.trainable = True\n",
        "                # Now recurse to freeze only BN layers inside it.\n",
        "                unfreeze_except_bn(layer)\n",
        "            elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "                layer.trainable = False\n",
        "            else:\n",
        "                layer.trainable = True\n",
        "\n",
        "    unfreeze_except_bn(model)\n",
        "\n",
        "    # Recompile with a much lower learning rate\n",
        "    # This is critical: a high LR would destroy the pretrained features\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=FINE_TUNING_LR),\n",
        "        loss=combined_loss,\n",
        "        metrics=[\n",
        "            DiceCoefficient(),\n",
        "            IoUCoefficient()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "    non_trainable_params = sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights])\n",
        "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "    print(f\"  Non-trainable parameters: {non_trainable_params:,}\")\n",
        "\n",
        "    # Sanity check: verify unfreezing actually worked\n",
        "    if trainable_params == 0:\n",
        "        print(\"\\n‚ö†Ô∏è WARNING: No trainable parameters! Something went wrong with unfreezing.\")\n",
        "    else:\n",
        "        print(f\"\\nModel recompiled for fine-tuning!\")\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Build SEPARATE callbacks for fine-tuning.\n",
        "    # Phase 1 callbacks have aggressive settings (EarlyStopping patience=2,\n",
        "    # ReduceLROnPlateau) that kill fine-tuning before it has time to adapt.\n",
        "    # Fine-tuning needs more patience because:\n",
        "    # - The backbone needs several epochs to adjust to the new task\n",
        "    # - The LR is already very low, so progress is slow but steady\n",
        "    # ------------------------------------------------------------------\n",
        "    ft_callbacks = []\n",
        "\n",
        "    # Model checkpoint for best fine-tuned model\n",
        "    ft_best_path = BEST_MODEL_PATH.replace('.keras', '_finetuned.keras') if '.keras' in BEST_MODEL_PATH else BEST_MODEL_PATH + '_finetuned'\n",
        "    ft_callbacks.append(\n",
        "        ModelCheckpoint(\n",
        "            ft_best_path,\n",
        "            monitor='val_iou_coefficient',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1,\n",
        "            save_weights_only=False\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Early stopping with MORE patience for fine-tuning\n",
        "    ft_callbacks.append(\n",
        "        EarlyStopping(\n",
        "            monitor='val_iou_coefficient',\n",
        "            patience=10,  # Much more patient than Phase 1\n",
        "            mode='max',\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Keep training time tracking\n",
        "    ft_time_callback = TrainingTimeCallback()\n",
        "    ft_callbacks.append(ft_time_callback)\n",
        "\n",
        "    # Prediction visualization callback (predictions vs ground truth)\n",
        "    if VISUALIZE_PREDICTIONS:\n",
        "        ft_viz_callback = PredictionVisualizationFromGenerator(\n",
        "            validation_generator=val_gen,\n",
        "            output_dir=OUTPUT_DIR,\n",
        "            num_samples=4,\n",
        "            frequency=EPOCHS  # Only on last epoch\n",
        "        )\n",
        "        ft_callbacks.append(ft_viz_callback)\n",
        "        print(f\"  Visualization callback added (last epoch only)\")\n",
        "\n",
        "    # MLflow callbacks (fresh instances)\n",
        "    if USE_MLFLOW and mlflow_tracker and MLFLOW_AVAILABLE:\n",
        "        ft_callbacks.append(MLflowCallback(tracker=mlflow_tracker))\n",
        "\n",
        "        # MLflow visualization callback to log images as artifacts\n",
        "        if VISUALIZE_PREDICTIONS:\n",
        "            ft_callbacks.append(MLflowVisualizationCallback(\n",
        "                mlflow_tracker=mlflow_tracker,\n",
        "                visualization_dir=OUTPUT_DIR\n",
        "            ))\n",
        "\n",
        "    # Start MLflow run for fine-tuning phase\n",
        "    if USE_MLFLOW and mlflow_tracker:\n",
        "        run_name = f\"{model_type}_finetune_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        mlflow_tracker.start_run(run_name=run_name)\n",
        "        mlflow_tracker.log_params({\n",
        "            \"phase\": \"fine_tuning\",\n",
        "            \"model_type\": model_type,\n",
        "            \"fine_tuning_lr\": FINE_TUNING_LR,\n",
        "            \"fine_tuning_epochs\": EPOCHS,\n",
        "            \"backbone_frozen\": False,\n",
        "            \"trainable_params\": trainable_params,\n",
        "            \"non_trainable_params\": non_trainable_params\n",
        "        })\n",
        "\n",
        "    # Continue training (fine-tuning) with dedicated callbacks\n",
        "    history_fine = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=ft_callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    # Check and update global best model\n",
        "    print(\"\\nChecking for global best model (Phase 2)...\")\n",
        "    if 'update_global_best' in globals():\n",
        "        update_global_best(history_fine, model, \"Phase2_Finetuning\")\n",
        "    else:\n",
        "        print(\"update_global_best function not defined. Skipping global best check.\")\n",
        "    # End MLflow run\n",
        "    if USE_MLFLOW and mlflow_tracker:\n",
        "        mlflow_tracker.end_run()\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Fine-tuning completed!\")\n",
        "else:\n",
        "    print(\"Skipping fine-tuning (backbone was not frozen or not using a backbone model)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf_uvfTebc3G"
      },
      "source": [
        "## 6.1 Visualize Feature Maps\n",
        "\n",
        "Extract and plot intermediate layer activations (feature maps) from the encoder/backbone. For U-Net MobileNet and DeepLabV3, default layers are the MobileNetV2 blocks (block_1_expand_relu, block_3_expand_relu, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHS-1rtdbc3G"
      },
      "outputs": [],
      "source": [
        "# Build feature-map extractor and plot activations (run after training)\n",
        "import matplotlib.pyplot as plt\n",
        "from src.feature_maps import get_feature_map_model, plot_feature_maps\n",
        "\n",
        "# Get a batch (e.g. from validation)\n",
        "val_images, val_masks = val_gen[0]\n",
        "batch = val_images[:4]  # use first 4 samples\n",
        "\n",
        "# Build sub-model that outputs intermediate layer activations\n",
        "# layer_names=None uses defaults for MobileNetV2 (U-Net MobileNet / DeepLabV3)\n",
        "feature_model, layer_names_used = get_feature_map_model(model, layer_names=None)\n",
        "print(\"Feature map layers:\", layer_names_used)\n",
        "\n",
        "# Plot feature maps for sample 0 (first image in batch)\n",
        "plot_feature_maps(\n",
        "    feature_model,\n",
        "    batch,\n",
        "    layer_names_used,\n",
        "    sample_idx=0,\n",
        "    max_channels=16,\n",
        "    figsize=(16, 12),\n",
        "    cmap=\"viridis\",\n",
        "    save_path=os.path.join(OUTPUT_DIR, \"feature_maps.png\") if 'OUTPUT_DIR' in dir() else None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hypertuning"
      ],
      "metadata": {
        "id": "lSTQirDOXdBA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "281d8906"
      },
      "source": [
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Check and update global best model\n",
        "print(\"\\nChecking for global best model...\")\n",
        "if 'update_global_best' in globals():\n",
        "    update_global_best(history, model, \"Phase1_Training\")\n",
        "else:\n",
        "    print(\"update_global_best function not defined. Skipping global best check.\")\n",
        "\n",
        "\n",
        "# End MLflow run\n",
        "if USE_MLFLOW and mlflow_tracker:\n",
        "    mlflow_tracker.end_run()\n",
        "print(\"=\" * 60)\n",
        "print(\"Training completed!\")\n",
        "print(f\"\\nBest model saved to: {MODEL_SAVE_PATH}\")\n",
        "if VISUALIZE_PREDICTIONS:\n",
        "    print(f\"Visualizations saved to: {OUTPUT_DIR}/\")\n",
        "print(f\"TensorBoard logs saved to: {LOGS_DIR}/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e88a731"
      },
      "source": [
        "# Phase 2: Fine-tuning - unfreeze backbone and train with lower learning rate\n",
        "# Applies to any model that uses a frozen MobileNetV2 backbone:\n",
        "# - U-Net + MobileNetV2\n",
        "# - DeepLabV3 (always uses MobileNetV2 backbone)\n",
        "# - DeepLabV3 with MobileNetV2 backbone (convenience wrapper)\n",
        "uses_backbone = USE_MOBILENET_BACKBONE or USE_DEEPLABV3 or USE_DEEPLABV3_WITH_BACKBONE\n",
        "\n",
        "if uses_backbone and FREEZE_BACKBONE:\n",
        "    # Determine model type name for logging\n",
        "    if USE_MOBILENET_BACKBONE:\n",
        "        model_type = \"UNet_MobileNetV2\"\n",
        "    elif USE_DEEPLABV3:\n",
        "        model_type = \"DeepLabV3\"\n",
        "    elif USE_DEEPLABV3_WITH_BACKBONE:\n",
        "        model_type = \"DeepLabV3_MobileNetV2\"\n",
        "\n",
        "    if USE_AUGMENTATION:\n",
        "      model_type = \"Augmented_\" + model_type\n",
        "    elif USE_LIGHT_AUGMENTATION:\n",
        "      model_type = \"LightAugmented\" + model_type\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Phase 2: Fine-tuning the entire {model_type} model\")\n",
        "    print(f\"  Unfreezing backbone...\")\n",
        "    print(f\"  Fine-tuning learning rate: {FINE_TUNING_LR}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Unfreeze all layers EXCEPT BatchNormalization.\n",
        "    # BN layers must stay frozen during fine-tuning because:\n",
        "    # - When trainable, BN recomputes statistics from each mini-batch\n",
        "    # - With small batches (e.g. 8), these statistics are noisy and unstable\n",
        "    # - This destabilizes the pretrained backbone and causes a loss spike\n",
        "    # Keeping BN frozen preserves the stable ImageNet statistics.\n",
        "    #\n",
        "    # IMPORTANT: We must traverse layers recursively because MobileNetV2\n",
        "    # may be nested as a sub-model inside the main model.\n",
        "    # ALSO: A sub-model's trainable=False OVERRIDES individual layer\n",
        "    # settings. So we must first set the sub-model to trainable=True\n",
        "    # (which propagates to all its layers), then freeze BN individually.\n",
        "    def unfreeze_except_bn(target_model):\n",
        "        for layer in target_model.layers:\n",
        "            if hasattr(layer, 'layers'):\n",
        "                # This is a nested sub-model (e.g. MobileNetV2).\n",
        "                # Setting trainable=True propagates to ALL its sublayers.\n",
        "                layer.trainable = True\n",
        "                # Now recurse to freeze only BN layers inside it.\n",
        "                unfreeze_except_bn(layer)\n",
        "            elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "                layer.trainable = False\n",
        "            else:\n",
        "                layer.trainable = True\n",
        "\n",
        "    unfreeze_except_bn(model)\n",
        "\n",
        "    # Recompile with a much lower learning rate\n",
        "    # This is critical: a high LR would destroy the pretrained features\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=FINE_TUNING_LR),\n",
        "        loss=combined_loss,\n",
        "        metrics=[\n",
        "            DiceCoefficient(),\n",
        "            IoUCoefficient()\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    trainable_params = sum([tf.keras.backend.count_params(w) for w in model.trainable_weights])\n",
        "    non_trainable_params = sum([tf.keras.backend.count_params(w) for w in model.non_trainable_weights])\n",
        "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "    print(f\"  Non-trainable parameters: {non_trainable_params:,}\")\n",
        "\n",
        "    # Sanity check: verify unfreezing actually worked\n",
        "    if trainable_params == 0:\n",
        "        print(\"\\n‚ö†Ô∏è WARNING: No trainable parameters! Something went wrong with unfreezing.\")\n",
        "    else:\n",
        "        print(f\"\\nModel recompiled for fine-tuning!\")\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Build SEPARATE callbacks for fine-tuning.\n",
        "    # Phase 1 callbacks have aggressive settings (EarlyStopping patience=2,\n",
        "    # ReduceLROnPlateau) that kill fine-tuning before it has time to adapt.\n",
        "    # Fine-tuning needs more patience because:\n",
        "    # - The backbone needs several epochs to adjust to the new task\n",
        "    # - The LR is already very low, so progress is slow but steady\n",
        "    # ------------------------------------------------------------------\n",
        "    ft_callbacks = []\n",
        "\n",
        "    # Model checkpoint for best fine-tuned model\n",
        "    ft_best_path = BEST_MODEL_PATH.replace('.keras', '_finetuned.keras') if '.keras' in BEST_MODEL_PATH else BEST_MODEL_PATH + '_finetuned'\n",
        "    ft_callbacks.append(\n",
        "        ModelCheckpoint(\n",
        "            ft_best_path,\n",
        "            monitor='val_iou_coefficient',\n",
        "            save_best_only=True,\n",
        "            mode='max',\n",
        "            verbose=1,\n",
        "            save_weights_only=False\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Early stopping with MORE patience for fine-tuning\n",
        "    ft_callbacks.append(\n",
        "        EarlyStopping(\n",
        "            monitor='val_iou_coefficient',\n",
        "            patience=7,  # Much more patient than Phase 1\n",
        "            mode='max',\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Keep training time tracking\n",
        "    ft_time_callback = TrainingTimeCallback()\n",
        "    ft_callbacks.append(ft_time_callback)\n",
        "\n",
        "    # Prediction visualization callback (predictions vs ground truth)\n",
        "    if VISUALIZE_PREDICTIONS:\n",
        "        ft_viz_callback = PredictionVisualizationFromGenerator(\n",
        "            validation_generator=val_gen,\n",
        "            output_dir=OUTPUT_DIR,\n",
        "            num_samples=4,\n",
        "            frequency=EPOCHS  # Only on last epoch\n",
        "        )\n",
        "        ft_callbacks.append(ft_viz_callback)\n",
        "        print(f\"  Visualization callback added (last epoch only)\")\n",
        "\n",
        "    # MLflow callbacks (fresh instances)\n",
        "    if USE_MLFLOW and mlflow_tracker and MLFLOW_AVAILABLE:\n",
        "        ft_callbacks.append(MLflowCallback(tracker=mlflow_tracker))\n",
        "\n",
        "        # MLflow visualization callback to log images as artifacts\n",
        "        if VISUALIZE_PREDICTIONS:\n",
        "            ft_callbacks.append(MLflowVisualizationCallback(\n",
        "                mlflow_tracker=mlflow_tracker,\n",
        "                visualization_dir=OUTPUT_DIR\n",
        "            ))\n",
        "\n",
        "    # Start MLflow run for fine-tuning phase\n",
        "    if USE_MLFLOW and mlflow_tracker:\n",
        "        run_name = f\"{model_type}_finetune_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        mlflow_tracker.start_run(run_name=run_name)\n",
        "        mlflow_tracker.log_params({\n",
        "            \"phase\": \"fine_tuning\",\n",
        "            \"model_type\": model_type,\n",
        "            \"fine_tuning_lr\": FINE_TUNING_LR,\n",
        "            \"fine_tuning_epochs\": EPOCHS,\n",
        "            \"backbone_frozen\": False,\n",
        "            \"trainable_params\": trainable_params,\n",
        "            \"non_trainable_params\": non_trainable_params\n",
        "        })\n",
        "\n",
        "    # Continue training (fine-tuning) with dedicated callbacks\n",
        "    history_fine = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=ft_callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Check and update global best model\n",
        "    print(\"\\nChecking for global best model (Phase 2)...\")\n",
        "    if 'update_global_best' in globals():\n",
        "        update_global_best(history_fine, model, \"Phase2_Finetuning\")\n",
        "    else:\n",
        "        print(\"update_global_best function not defined. Skipping global best check.\")\n",
        "\n",
        "    # End MLflow run\n",
        "    if USE_MLFLOW and mlflow_tracker:\n",
        "        mlflow_tracker.end_run()\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Fine-tuning completed!\")\n",
        "else:\n",
        "    print(\"Skipping fine-tuning (backbone was not frozen or not using a backbone model)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Optimization of the Global Best Model\n",
        "\n",
        "This section uses **Bayesian optimization** (Optuna TPE sampler) to find optimal hyperparameters for improving the global best model.\n",
        "\n",
        "**Parameters to optimize:**\n",
        "- Learning rate (Phase 1)\n",
        "- Batch size\n",
        "- Fine-tuning learning rate (Phase 2)\n",
        "\n",
        "**Note:** Each trial trains a model from scratch with sampled hyperparameters. Reduce `N_TRIALS` or `EPOCHS_PER_TRIAL` for faster experimentation."
      ],
      "metadata": {
        "id": "avjXfajlOlNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian optimization configuration\n",
        "import optuna\n",
        "\n",
        "N_TRIALS = 20  # Number of trials (adjust based on available time)\n",
        "EPOCHS_PER_TRIAL = 10  # Reduced epochs per trial for faster search\n",
        "OPTIMIZATION_STUDY_NAME = \"global_best_hyperopt\"\n",
        "\n",
        "print(f\"Optuna optimization: {N_TRIALS} trials, {EPOCHS_PER_TRIAL} epochs per trial\")"
      ],
      "metadata": {
        "id": "Bh4vVPMPOuZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective function for Bayesian optimization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import gc\n",
        "\n",
        "def create_optuna_objective(train_aug, IMAGE_SIZE, N_CLASSES, USE_MOBILENET_BACKBONE,\n",
        "                            MOBILENET_ALPHA, DECODER_FILTERS, FREEZE_BACKBONE, MOBILENET_WEIGHTS,\n",
        "                            VALIDATION_SPLIT, EPOCHS_PER_TRIAL, INITIAL_FILTERS=64):\n",
        "    \"\"\"Create objective function that closes over notebook config.\"\"\"\n",
        "    def objective(trial):\n",
        "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
        "        batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
        "        # fine_tuning_lr for final training (Phase 1 only in trials for speed)\n",
        "        trial.suggest_float(\"fine_tuning_lr\", 1e-6, 1e-4, log=True)\n",
        "\n",
        "        # Create data generators with trial batch_size\n",
        "        train_gen_trial, val_gen_trial = create_data_generators(\n",
        "            batch_size=batch_size,\n",
        "            dim=IMAGE_SIZE,\n",
        "            augmentation=train_aug,\n",
        "            normalize=True,\n",
        "            validation_split=VALIDATION_SPLIT,\n",
        "        )\n",
        "\n",
        "        # Build model (same architecture as main pipeline)\n",
        "        if USE_MOBILENET_BACKBONE:\n",
        "            model = build_unet_mobilenet(\n",
        "                input_shape=(*IMAGE_SIZE, 3),\n",
        "                n_classes=N_CLASSES,\n",
        "                alpha=MOBILENET_ALPHA,\n",
        "                weights=MOBILENET_WEIGHTS,\n",
        "                decoder_filters=DECODER_FILTERS,\n",
        "                freeze_backbone=FREEZE_BACKBONE,\n",
        "            )\n",
        "        else:\n",
        "            model = build_unet(\n",
        "                input_shape=(*IMAGE_SIZE, 3),\n",
        "                n_classes=N_CLASSES,\n",
        "                filters=INITIAL_FILTERS,\n",
        "            )\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=learning_rate),\n",
        "            loss=combined_loss,\n",
        "            metrics=[\"accuracy\", DiceCoefficient(), IoUCoefficient()],\n",
        "        )\n",
        "\n",
        "        # Lightweight callbacks for trials\n",
        "        trial_callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor=\"val_iou_coefficient\",\n",
        "                patience=3,\n",
        "                mode=\"max\",\n",
        "                restore_best_weights=True,\n",
        "                verbose=0,\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "        history = model.fit(\n",
        "            train_gen_trial,\n",
        "            validation_data=val_gen_trial,\n",
        "            epochs=EPOCHS_PER_TRIAL,\n",
        "            callbacks=trial_callbacks,\n",
        "            verbose=0,\n",
        "        )\n",
        "\n",
        "        best_val_iou = max(history.history[\"val_iou_coefficient\"])\n",
        "        best_val_dice = max(history.history[\"val_dice_coefficient\"])\n",
        "        best_val_loss = min(history.history[\"val_loss\"])\n",
        "        trial.set_user_attr(\"val_dice_coefficient\", float(best_val_dice))\n",
        "        trial.set_user_attr(\"val_loss\", float(best_val_loss))\n",
        "\n",
        "        del model\n",
        "        gc.collect()\n",
        "        return best_val_iou\n",
        "\n",
        "    return objective\n",
        "\n",
        "# Create objective with current notebook config\n",
        "objective_fn = create_optuna_objective(\n",
        "    train_aug, IMAGE_SIZE, N_CLASSES, USE_MOBILENET_BACKBONE,\n",
        "    MOBILENET_ALPHA, DECODER_FILTERS, FREEZE_BACKBONE, MOBILENET_WEIGHTS,\n",
        "    VALIDATION_SPLIT, EPOCHS_PER_TRIAL, INITIAL_FILTERS,\n",
        ")\n",
        "print(\"Objective function created.\")"
      ],
      "metadata": {
        "id": "oAAWbK4zPEVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Optuna study\n",
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\", study_name=OPTIMIZATION_STUDY_NAME)\n",
        "t_start = time.time()\n",
        "study.optimize(objective_fn, n_trials=N_TRIALS, show_progress_bar=True, n_jobs=1)\n",
        "total_optimization_time_seconds = time.time() - t_start\n",
        "\n",
        "print(f\"\\nBest trial val_iou: {study.best_value:.4f}\")\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(f\"Total optimization time: {total_optimization_time_seconds:.1f}s\")\n",
        "\n",
        "# Persist optimization metrics (DICE, Loss, time) to JSON\n",
        "OPTIMIZATION_METRICS_PATH = Path(GLOBAL_BEST_MODEL_PATH).parent / \"optimization_metrics.json\"\n",
        "trials_data = []\n",
        "for t in study.trials:\n",
        "    if t.state == optuna.trial.TrialState.COMPLETE and t.value is not None:\n",
        "        trial_record = {\n",
        "            \"trial_number\": t.number,\n",
        "            \"val_iou_coefficient\": float(t.value),\n",
        "            \"val_dice_coefficient\": float(t.user_attrs.get(\"val_dice_coefficient\", 0.0)),\n",
        "            \"val_loss\": float(t.user_attrs['val_loss']) if 'val_loss' in t.user_attrs else None,\n",
        "            \"duration_seconds\": t.duration.total_seconds() if t.duration else None,\n",
        "            \"params\": t.params,\n",
        "        }\n",
        "        trials_data.append(trial_record)\n",
        "\n",
        "metrics_payload = {\n",
        "    \"study_name\": OPTIMIZATION_STUDY_NAME,\n",
        "    \"total_optimization_time_seconds\": total_optimization_time_seconds,\n",
        "    \"n_trials\": len(trials_data),\n",
        "    \"best_trial_number\": study.best_trial.number if study.best_trial else None,\n",
        "    \"best_params\": study.best_params,\n",
        "    \"trials\": trials_data,\n",
        "}\n",
        "\n",
        "with open(OPTIMIZATION_METRICS_PATH, \"w\") as f:\n",
        "    json.dump(metrics_payload, f, indent=2)\n",
        "\n",
        "print(f\"Optimization metrics saved to {OPTIMIZATION_METRICS_PATH}\")"
      ],
      "metadata": {
        "id": "5R3Hh6y9PamS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final training with best hyperparameters and update global best\n",
        "best_params = study.best_params\n",
        "opt_lr = best_params[\"learning_rate\"]\n",
        "opt_batch_size = best_params[\"batch_size\"]\n",
        "opt_fine_tuning_lr = best_params[\"fine_tuning_lr\"]\n",
        "\n",
        "print(f\"Training final model with best params: lr={opt_lr:.2e}, batch_size={opt_batch_size}, fine_tuning_lr={opt_fine_tuning_lr:.2e}\")\n",
        "\n",
        "# Create generators with optimal batch size\n",
        "train_gen_opt, val_gen_opt = create_data_generators(\n",
        "    batch_size=opt_batch_size,\n",
        "    dim=IMAGE_SIZE,\n",
        "    augmentation=train_aug,\n",
        "    normalize=True,\n",
        "    validation_split=VALIDATION_SPLIT,\n",
        ")\n",
        "\n",
        "# Build and compile model\n",
        "if USE_MOBILENET_BACKBONE:\n",
        "    model = build_unet_mobilenet(\n",
        "        input_shape=(*IMAGE_SIZE, 3),\n",
        "        n_classes=N_CLASSES,\n",
        "        alpha=MOBILENET_ALPHA,\n",
        "        weights=MOBILENET_WEIGHTS,\n",
        "        decoder_filters=DECODER_FILTERS,\n",
        "        freeze_backbone=FREEZE_BACKBONE,\n",
        "    )\n",
        "else:\n",
        "    model = build_unet(\n",
        "        input_shape=(*IMAGE_SIZE, 3),\n",
        "        n_classes=N_CLASSES,\n",
        "        filters=INITIAL_FILTERS,\n",
        "    )\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=opt_lr),\n",
        "    loss=combined_loss,\n",
        "    metrics=[DiceCoefficient(), IoUCoefficient()],\n",
        ")\n",
        "\n",
        "# Phase 1 training with full callbacks\n",
        "callbacks_opt = [\n",
        "    ModelCheckpoint(\n",
        "        BEST_MODEL_PATH.replace(\".keras\", \"_optuna.keras\"),\n",
        "        monitor=\"val_iou_coefficient\",\n",
        "        save_best_only=True,\n",
        "        mode=\"max\",\n",
        "        verbose=1,\n",
        "        save_weights_only=False,\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_iou_coefficient\",\n",
        "        patience=EARLY_STOPPING_PATIENCE,\n",
        "        mode=\"max\",\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "    ),\n",
        "]\n",
        "\n",
        "history_phase1 = model.fit(\n",
        "    train_gen_opt,\n",
        "    validation_data=val_gen_opt,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks_opt,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Phase 2 fine-tuning if using backbone\n",
        "if FREEZE_BACKBONE and USE_MOBILENET_BACKBONE:\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = True\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=opt_fine_tuning_lr),\n",
        "        loss=combined_loss,\n",
        "        metrics=[DiceCoefficient(), IoUCoefficient()],\n",
        "    )\n",
        "    history_phase2 = model.fit(\n",
        "        train_gen_opt,\n",
        "        validation_data=val_gen_opt,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks_opt,\n",
        "        verbose=1,\n",
        "    )\n",
        "    # Combine histories for update_global_best (use best val_iou from both phases)\n",
        "    best_val_iou = max(\n",
        "        max(history_phase1.history[\"val_iou_coefficient\"]),\n",
        "        max(history_phase2.history[\"val_iou_coefficient\"]),\n",
        "    )\n",
        "    history_opt = type(\"History\", (), {\"history\": {\"val_iou_coefficient\": [best_val_iou]}})()\n",
        "else:\n",
        "    history_opt = history_phase1\n",
        "\n",
        "# Update global best if this model is better\n",
        "print(\"\\nChecking for global best model (Bayesian optimization)...\")\n",
        "if \"update_global_best\" in globals():\n",
        "    update_global_best(history_opt, model, \"BayesianOpt_Best\")\n",
        "else:\n",
        "    from src import utils\n",
        "    utils.update_global_best(\n",
        "        history_opt, model, \"BayesianOpt_Best\",\n",
        "        GLOBAL_BEST_MODEL_PATH, GLOBAL_BEST_METRICS_PATH, GLOBAL_BEST_METRICS_PATH,\n",
        "    )"
      ],
      "metadata": {
        "id": "ebw29HSuPMzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of predictions with best Optuna params\n",
        "OUTPUT_DIR_OPTUNA = str(Path(OUTPUT_DIR) / \"optuna_best\")\n",
        "Path(OUTPUT_DIR_OPTUNA).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "viz_callback_optuna = PredictionVisualizationFromGenerator(\n",
        "    validation_generator=val_gen_opt,\n",
        "    output_dir=OUTPUT_DIR_OPTUNA,\n",
        "    num_samples=4,\n",
        "    frequency=1,\n",
        ")\n",
        "viz_callback_optuna.set_model(model)\n",
        "viz_callback_optuna.on_epoch_end(epoch=0, logs=None)\n",
        "\n",
        "print(f\"Optuna best params predictions saved to {OUTPUT_DIR_OPTUNA}/\")"
      ],
      "metadata": {
        "id": "Z2zyVJI2cLTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of optimization results\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best validation IoU:\", study.best_value)\n",
        "\n",
        "# Optimization history plot\n",
        "fig = optuna.visualization.plot_optimization_history(study)\n",
        "fig.show()  # In Jupyter/Colab, the figure is displayed automatically"
      ],
      "metadata": {
        "id": "AzIje0SQhmCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation du mod√®le optimis√© ‚Äì Performance par classes\n",
        "\n",
        "On charge le meilleur mod√®le (global best ou, en secours, le checkpoint Optuna) et on affiche les m√©triques **par classe** sur le jeu de validation : IoU et optionnellement Dice par cat√©gorie Cityscapes, ainsi qu‚Äôun tableau r√©capitulatif et un bar chart pour une lecture rapide."
      ],
      "metadata": {
        "id": "jSgNdZjVGL59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load optimized model (global best or Optuna fallback) ---\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from src.metrics import combined_loss, DiceCoefficient, IoUCoefficient\n",
        "from src.utils import CATEGORY_NAMES\n",
        "\n",
        "if Path(GLOBAL_BEST_MODEL_PATH).exists():\n",
        "    model_path = GLOBAL_BEST_MODEL_PATH\n",
        "    print(f\"Loading global best model: {model_path}\")\n",
        "else:\n",
        "    model_path = BEST_MODEL_PATH.replace(\".keras\", \"_optuna.keras\")\n",
        "    print(f\"Loading Optuna checkpoint: {model_path}\")\n",
        "\n",
        "model = keras.models.load_model(\n",
        "    model_path,\n",
        "    custom_objects={\n",
        "        \"combined_loss\": combined_loss,\n",
        "        \"DiceCoefficient\": DiceCoefficient,\n",
        "        \"IoUCoefficient\": IoUCoefficient,\n",
        "    },\n",
        "    safe_mode=False  # Allow loading Lambda layers defined as Python lambdas\n",
        ")\n",
        "\n",
        "# --- Validation generator: reuse val_gen_opt or recreate ---\n",
        "if \"val_gen_opt\" in globals():\n",
        "    val_gen = val_gen_opt\n",
        "    print(\"Using existing val_gen_opt\")\n",
        "else:\n",
        "    batch_size = opt_batch_size if \"opt_batch_size\" in globals() else 32\n",
        "    _, val_gen = create_data_generators(\n",
        "        batch_size=batch_size,\n",
        "        dim=IMAGE_SIZE,\n",
        "        augmentation=None,\n",
        "        normalize=True,\n",
        "        validation_split=VALIDATION_SPLIT,\n",
        "    )\n",
        "    print(f\"Recreated validation generator (batch_size={batch_size})\")\n",
        "\n",
        "# --- Accumulate intersection, union, pixel counts, and confusion matrix over all batches ---\n",
        "n_classes = N_CLASSES\n",
        "intersection = np.zeros(n_classes, dtype=np.float64)\n",
        "count_true = np.zeros(n_classes, dtype=np.float64)\n",
        "count_pred = np.zeros(n_classes, dtype=np.float64)\n",
        "cm = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
        "\n",
        "for batch_idx in range(len(val_gen)):\n",
        "    images, masks = val_gen[batch_idx]\n",
        "    y_true = np.squeeze(masks).astype(np.int32)\n",
        "    if y_true.ndim == 2:\n",
        "        y_true = y_true[np.newaxis, ...]\n",
        "    preds = model.predict(images, verbose=0)\n",
        "    y_pred = np.argmax(preds, axis=-1).astype(np.int32)\n",
        "    for c in range(n_classes):\n",
        "        inter_c = np.sum((y_true == c) & (y_pred == c))\n",
        "        intersection[c] += inter_c\n",
        "        count_true[c] += np.sum(y_true == c)\n",
        "        count_pred[c] += np.sum(y_pred == c)\n",
        "    cm_batch = confusion_matrix(\n",
        "        y_true.ravel(), y_pred.ravel(), labels=list(range(n_classes))\n",
        "    )\n",
        "    cm += cm_batch\n",
        "\n",
        "union = count_true + count_pred - intersection\n",
        "iou_per_class = np.zeros(n_classes)\n",
        "dice_per_class = np.zeros(n_classes)\n",
        "for c in range(n_classes):\n",
        "    iou_per_class[c] = intersection[c] / (union[c] + 1e-6)\n",
        "    dice_per_class[c] = 2 * intersection[c] / (count_true[c] + count_pred[c] + 1e-6)\n",
        "\n",
        "# --- Table: class name, IoU, Dice, pixel count (GT) ---\n",
        "import pandas as pd\n",
        "rows = []\n",
        "for c in range(n_classes):\n",
        "    rows.append({\n",
        "        \"Class\": c,\n",
        "        \"Name\": CATEGORY_NAMES.get(c, f\"class_{c}\"),\n",
        "        \"IoU\": round(iou_per_class[c], 4),\n",
        "        \"Dice\": round(dice_per_class[c], 4),\n",
        "        \"Pixels (GT)\": int(count_true[c]),\n",
        "    })\n",
        "df_metrics = pd.DataFrame(rows)\n",
        "print(\"Per-class metrics on validation set:\\n\")\n",
        "display(df_metrics)\n",
        "print(f\"\\nMean IoU: {np.mean(iou_per_class):.4f}\")\n",
        "\n",
        "# --- Bar chart: IoU per class ---\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "names = [CATEGORY_NAMES.get(c, str(c)) for c in range(n_classes)]\n",
        "ax.bar(names, iou_per_class, color=\"steelblue\", edgecolor=\"black\")\n",
        "ax.set_ylabel(\"IoU\")\n",
        "ax.set_title(\"Validation IoU per class (optimized model)\")\n",
        "ax.set_ylim(0, 1)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Optional: confusion matrix (pixel counts) ---\n",
        "fig2, ax2 = plt.subplots(figsize=(8, 8))\n",
        "im = ax2.imshow(cm, cmap=\"Blues\")\n",
        "ax2.set_xticks(range(n_classes))\n",
        "ax2.set_yticks(range(n_classes))\n",
        "ax2.set_xticklabels([CATEGORY_NAMES.get(c, str(c)) for c in range(n_classes)], rotation=45, ha=\"right\")\n",
        "ax2.set_yticklabels([CATEGORY_NAMES.get(c, str(c)) for c in range(n_classes)])\n",
        "ax2.set_xlabel(\"Predicted\")\n",
        "ax2.set_ylabel(\"True\")\n",
        "plt.colorbar(im, ax=ax2, label=\"Pixel count\")\n",
        "ax2.set_title(\"Confusion matrix (validation, pixel counts)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AFTJFEcLGNSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload optimized model to Azure\n",
        "\n",
        "Save the global best model (potentially updated by Bayesian optimization) to Azure Blob Storage."
      ],
      "metadata": {
        "id": "GD9FrX_OTbDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload optimized model to Azure Blob Storage\n",
        "import importlib\n",
        "import src.azure_storage\n",
        "import os\n",
        "# Force reload to pick up the newly installed azure-storage-blob package\n",
        "importlib.reload(src.azure_storage)\n",
        "\n",
        "try:\n",
        "    from src.azure_storage import AzureStorageManager\n",
        "    from pathlib import Path\n",
        "\n",
        "    # Try to retrieve connection string from Colab secrets or environment\n",
        "    connection_string = None\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        connection_string = userdata.get('AZURE_STORAGE_CONNECTION_STRING')\n",
        "    except (ImportError, Exception):\n",
        "        # Fallback to os.getenv if not in Colab or secret not found\n",
        "        connection_string = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n",
        "\n",
        "    if not connection_string:\n",
        "        print(\"‚ö†Ô∏è Warning: AZURE_STORAGE_CONNECTION_STRING not found in Colab secrets or environment variables.\")\n",
        "\n",
        "    # Pass connection_string explicitly.\n",
        "    azure_manager = AzureStorageManager(\n",
        "        connection_string=connection_string,\n",
        "        container_name=AZURE_CONTAINER_NAME,\n",
        "        create_container_if_not_exists=AZURE_CREATE_CONTAINER,\n",
        "    )\n",
        "\n",
        "    run_name = f\"{AZURE_RUN_NAME}_optuna\" if AZURE_RUN_NAME else \"bayesian_opt\"\n",
        "    blob_name = f\"{run_name}/model/global_best_model.keras\"\n",
        "\n",
        "    if Path(GLOBAL_BEST_MODEL_PATH).exists():\n",
        "        url = azure_manager.upload_file(\n",
        "            GLOBAL_BEST_MODEL_PATH,\n",
        "            blob_name=blob_name,\n",
        "            overwrite=True,\n",
        "        )\n",
        "        print(f\"Optimized model uploaded to Azure: {url}\")\n",
        "    else:\n",
        "        # Fallback: upload optuna-specific model if global best path is missing\n",
        "        optuna_model_path = BEST_MODEL_PATH.replace(\".keras\", \"_optuna.keras\")\n",
        "        if Path(optuna_model_path).exists():\n",
        "            url = azure_manager.upload_file(\n",
        "                optuna_model_path,\n",
        "                blob_name=f\"{run_name}/model/best_model_optuna.keras\",\n",
        "                overwrite=True,\n",
        "            )\n",
        "            print(f\"Optimized model uploaded to Azure: {url}\")\n",
        "        else:\n",
        "            print(\"No model file found to upload. Ensure the training cell ran successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Azure upload failed: {e}\")\n",
        "    print(\"Ensure AZURE_STORAGE_CONNECTION_STRING is set in Colab secrets (key icon on the left).\")"
      ],
      "metadata": {
        "id": "yCPEdlTkTfoE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}